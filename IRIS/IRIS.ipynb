{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/handsomekiwi/JupyterPractice/blob/master/IRIS/IRIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC6StjRhFjrz",
        "colab_type": "code",
        "outputId": "0f1bd595-f042-49f2-eba4-d6c8924ff52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import pandas as pd\n",
        "# load dataset\n",
        "dataframe = pd.read_csv(\"https://raw.githubusercontent.com/handsomekiwi/JupyterPractice/master/IRIS/IRIS.csv\", header=None)\n",
        "#dataframe. add tab to find function\n",
        "dataframe.head() #.head gives the first 5 row\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sepal_length</td>\n",
              "      <td>sepal_width</td>\n",
              "      <td>petal_length</td>\n",
              "      <td>petal_width</td>\n",
              "      <td>species</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0            1             2            3            4\n",
              "0  sepal_length  sepal_width  petal_length  petal_width      species\n",
              "1           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "2           4.9            3           1.4          0.2  Iris-setosa\n",
              "3           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "4           4.6          3.1           1.5          0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqakbZQlEcYT",
        "colab_type": "code",
        "outputId": "99802b3e-615e-4c13-dfa7-cc6e00aa677a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "dataset = dataframe.values\n",
        "import numpy as np\n",
        "dataset = np.delete(dataset, (0), axis=0)\n",
        "dataset[0:5]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['5.1', '3.5', '1.4', '0.2', 'Iris-setosa'],\n",
              "       ['4.9', '3', '1.4', '0.2', 'Iris-setosa'],\n",
              "       ['4.7', '3.2', '1.3', '0.2', 'Iris-setosa'],\n",
              "       ['4.6', '3.1', '1.5', '0.2', 'Iris-setosa'],\n",
              "       ['5', '3.6', '1.4', '0.2', 'Iris-setosa']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znKj-_OEJc8Z",
        "colab_type": "code",
        "outputId": "6cca1c37-edd1-4421-b0fa-380481b46026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "X_input = dataset[:,0:4].astype(float)\n",
        "X_input[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt7AbDNOJkMp",
        "colab_type": "code",
        "outputId": "2895ee1f-bd80-4b70-f4ee-2c3bde1c39fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "Y_answer = dataset[:,4]\n",
        "Y_answer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
              "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
              "       'Iris-virginica', 'Iris-virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IziWYczFJpP5",
        "colab_type": "code",
        "outputId": "b9cd991b-31cb-4dcc-8239-b4f06370e8b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "encoded_Y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWsftsAuJxKh",
        "colab_type": "code",
        "outputId": "77f3d4ec-2b6e-4f91-dab4-6227748f50e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import utils as np_utils\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "dummy_y"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLl-SlvBMp0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#understand why use one hot encoding https://www.jianshu.com/p/cb344e1c860a\n",
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.OneHotEncoder()\n",
        "encoder.fit([\n",
        "    [0, 2, 1, 12],\n",
        "    [1, 3, 5, 3],\n",
        "    [2, 3, 2, 12],\n",
        "    [1, 2, 4, 3]\n",
        "])\n",
        "encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()\n",
        "print(\"\\n Encoded vector =\", encoded_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJMS4DkmNvx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#softmax是做分類問題(所有書區機率加起來等於1) sigmoid是坐二分類的問題(所有輸出機率加起來不一定等於1)\n",
        "def baseline_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(8,input_dim = 4 , activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  test = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=test,metrics=['accuracy'])\n",
        "  return model   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-iawwVtHC3v",
        "colab_type": "code",
        "outputId": "20d7c512-63d9-4c1a-819b-dfab666604fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = baseline_model();\n",
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 67\n",
            "Trainable params: 67\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_6620QCHInM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#4w+1b * 8neurons =40\n",
        "#8w+1b * 3neurons =27"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBIniuaSH_wd",
        "colab_type": "code",
        "outputId": "03048978-3901-4f59-cc32-8e7a9668ee88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_input,dummy_y,epochs=90,batch_size=5) #epochs = 最幾次訓練 batch_size =每次處理幾筆資料"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 3.0569 - acc: 0.3333\n",
            "Epoch 2/90\n",
            "150/150 [==============================] - 0s 237us/step - loss: 2.3743 - acc: 0.3333\n",
            "Epoch 3/90\n",
            "150/150 [==============================] - 0s 226us/step - loss: 1.8723 - acc: 0.3333\n",
            "Epoch 4/90\n",
            "150/150 [==============================] - 0s 239us/step - loss: 1.5258 - acc: 0.3333\n",
            "Epoch 5/90\n",
            "150/150 [==============================] - 0s 257us/step - loss: 1.2799 - acc: 0.4400\n",
            "Epoch 6/90\n",
            "150/150 [==============================] - 0s 218us/step - loss: 1.0849 - acc: 0.6200\n",
            "Epoch 7/90\n",
            "150/150 [==============================] - 0s 226us/step - loss: 0.9422 - acc: 0.6600\n",
            "Epoch 8/90\n",
            "150/150 [==============================] - 0s 248us/step - loss: 0.8494 - acc: 0.6667\n",
            "Epoch 9/90\n",
            "150/150 [==============================] - 0s 240us/step - loss: 0.7848 - acc: 0.6667\n",
            "Epoch 10/90\n",
            "150/150 [==============================] - 0s 309us/step - loss: 0.7445 - acc: 0.6667\n",
            "Epoch 11/90\n",
            "150/150 [==============================] - 0s 277us/step - loss: 0.7112 - acc: 0.6733\n",
            "Epoch 12/90\n",
            "150/150 [==============================] - 0s 297us/step - loss: 0.6861 - acc: 0.7000\n",
            "Epoch 13/90\n",
            "150/150 [==============================] - 0s 271us/step - loss: 0.6641 - acc: 0.7467\n",
            "Epoch 14/90\n",
            "150/150 [==============================] - 0s 325us/step - loss: 0.6446 - acc: 0.7267\n",
            "Epoch 15/90\n",
            "150/150 [==============================] - 0s 294us/step - loss: 0.6278 - acc: 0.7533\n",
            "Epoch 16/90\n",
            "150/150 [==============================] - 0s 293us/step - loss: 0.6095 - acc: 0.7667\n",
            "Epoch 17/90\n",
            "150/150 [==============================] - 0s 277us/step - loss: 0.5944 - acc: 0.7267\n",
            "Epoch 18/90\n",
            "150/150 [==============================] - 0s 274us/step - loss: 0.5803 - acc: 0.7400\n",
            "Epoch 19/90\n",
            "150/150 [==============================] - 0s 263us/step - loss: 0.5675 - acc: 0.7800\n",
            "Epoch 20/90\n",
            "150/150 [==============================] - 0s 283us/step - loss: 0.5560 - acc: 0.7733\n",
            "Epoch 21/90\n",
            "150/150 [==============================] - 0s 272us/step - loss: 0.5461 - acc: 0.7733\n",
            "Epoch 22/90\n",
            "150/150 [==============================] - 0s 300us/step - loss: 0.5353 - acc: 0.7867\n",
            "Epoch 23/90\n",
            "150/150 [==============================] - 0s 269us/step - loss: 0.5263 - acc: 0.7667\n",
            "Epoch 24/90\n",
            "150/150 [==============================] - 0s 285us/step - loss: 0.5193 - acc: 0.7400\n",
            "Epoch 25/90\n",
            "150/150 [==============================] - 0s 272us/step - loss: 0.5122 - acc: 0.8667\n",
            "Epoch 26/90\n",
            "150/150 [==============================] - 0s 433us/step - loss: 0.5046 - acc: 0.7867\n",
            "Epoch 27/90\n",
            "150/150 [==============================] - 0s 263us/step - loss: 0.4950 - acc: 0.8067\n",
            "Epoch 28/90\n",
            "150/150 [==============================] - 0s 270us/step - loss: 0.4914 - acc: 0.7533\n",
            "Epoch 29/90\n",
            "150/150 [==============================] - 0s 258us/step - loss: 0.4819 - acc: 0.8200\n",
            "Epoch 30/90\n",
            "150/150 [==============================] - 0s 265us/step - loss: 0.4785 - acc: 0.8400\n",
            "Epoch 31/90\n",
            "150/150 [==============================] - 0s 279us/step - loss: 0.4731 - acc: 0.8533\n",
            "Epoch 32/90\n",
            "150/150 [==============================] - 0s 258us/step - loss: 0.4688 - acc: 0.8000\n",
            "Epoch 33/90\n",
            "150/150 [==============================] - 0s 233us/step - loss: 0.4654 - acc: 0.8933\n",
            "Epoch 34/90\n",
            "150/150 [==============================] - 0s 246us/step - loss: 0.4560 - acc: 0.9067\n",
            "Epoch 35/90\n",
            "150/150 [==============================] - 0s 270us/step - loss: 0.4518 - acc: 0.8333\n",
            "Epoch 36/90\n",
            "150/150 [==============================] - 0s 280us/step - loss: 0.4480 - acc: 0.8133\n",
            "Epoch 37/90\n",
            "150/150 [==============================] - 0s 294us/step - loss: 0.4435 - acc: 0.8667\n",
            "Epoch 38/90\n",
            "150/150 [==============================] - 0s 236us/step - loss: 0.4393 - acc: 0.8867\n",
            "Epoch 39/90\n",
            "150/150 [==============================] - 0s 247us/step - loss: 0.4367 - acc: 0.8267\n",
            "Epoch 40/90\n",
            "150/150 [==============================] - 0s 264us/step - loss: 0.4314 - acc: 0.9200\n",
            "Epoch 41/90\n",
            "150/150 [==============================] - 0s 243us/step - loss: 0.4270 - acc: 0.9200\n",
            "Epoch 42/90\n",
            "150/150 [==============================] - 0s 240us/step - loss: 0.4250 - acc: 0.8533\n",
            "Epoch 43/90\n",
            "150/150 [==============================] - 0s 261us/step - loss: 0.4194 - acc: 0.9000\n",
            "Epoch 44/90\n",
            "150/150 [==============================] - 0s 257us/step - loss: 0.4180 - acc: 0.8800\n",
            "Epoch 45/90\n",
            "150/150 [==============================] - 0s 256us/step - loss: 0.4140 - acc: 0.9067\n",
            "Epoch 46/90\n",
            "150/150 [==============================] - 0s 292us/step - loss: 0.4108 - acc: 0.9467\n",
            "Epoch 47/90\n",
            "150/150 [==============================] - 0s 248us/step - loss: 0.4051 - acc: 0.9467\n",
            "Epoch 48/90\n",
            "150/150 [==============================] - 0s 240us/step - loss: 0.4030 - acc: 0.9333\n",
            "Epoch 49/90\n",
            "150/150 [==============================] - 0s 244us/step - loss: 0.4015 - acc: 0.9467\n",
            "Epoch 50/90\n",
            "150/150 [==============================] - 0s 246us/step - loss: 0.3979 - acc: 0.8733\n",
            "Epoch 51/90\n",
            "150/150 [==============================] - 0s 263us/step - loss: 0.3939 - acc: 0.9400\n",
            "Epoch 52/90\n",
            "150/150 [==============================] - 0s 267us/step - loss: 0.3885 - acc: 0.9467\n",
            "Epoch 53/90\n",
            "150/150 [==============================] - 0s 272us/step - loss: 0.3859 - acc: 0.9533\n",
            "Epoch 54/90\n",
            "150/150 [==============================] - 0s 238us/step - loss: 0.3826 - acc: 0.9200\n",
            "Epoch 55/90\n",
            "150/150 [==============================] - 0s 241us/step - loss: 0.3800 - acc: 0.9467\n",
            "Epoch 56/90\n",
            "150/150 [==============================] - 0s 256us/step - loss: 0.3749 - acc: 0.9467\n",
            "Epoch 57/90\n",
            "150/150 [==============================] - 0s 282us/step - loss: 0.3735 - acc: 0.9533\n",
            "Epoch 58/90\n",
            "150/150 [==============================] - 0s 272us/step - loss: 0.3678 - acc: 0.9533\n",
            "Epoch 59/90\n",
            "150/150 [==============================] - 0s 300us/step - loss: 0.3665 - acc: 0.9533\n",
            "Epoch 60/90\n",
            "150/150 [==============================] - 0s 251us/step - loss: 0.3614 - acc: 0.9533\n",
            "Epoch 61/90\n",
            "150/150 [==============================] - 0s 248us/step - loss: 0.3583 - acc: 0.9467\n",
            "Epoch 62/90\n",
            "150/150 [==============================] - 0s 249us/step - loss: 0.3559 - acc: 0.9533\n",
            "Epoch 63/90\n",
            "150/150 [==============================] - 0s 268us/step - loss: 0.3573 - acc: 0.9067\n",
            "Epoch 64/90\n",
            "150/150 [==============================] - 0s 248us/step - loss: 0.3467 - acc: 0.9400\n",
            "Epoch 65/90\n",
            "150/150 [==============================] - 0s 269us/step - loss: 0.3455 - acc: 0.9533\n",
            "Epoch 66/90\n",
            "150/150 [==============================] - 0s 267us/step - loss: 0.3430 - acc: 0.9467\n",
            "Epoch 67/90\n",
            "150/150 [==============================] - 0s 257us/step - loss: 0.3379 - acc: 0.9600\n",
            "Epoch 68/90\n",
            "150/150 [==============================] - 0s 267us/step - loss: 0.3385 - acc: 0.9400\n",
            "Epoch 69/90\n",
            "150/150 [==============================] - 0s 285us/step - loss: 0.3304 - acc: 0.9600\n",
            "Epoch 70/90\n",
            "150/150 [==============================] - 0s 268us/step - loss: 0.3300 - acc: 0.9600\n",
            "Epoch 71/90\n",
            "150/150 [==============================] - 0s 253us/step - loss: 0.3245 - acc: 0.9600\n",
            "Epoch 72/90\n",
            "150/150 [==============================] - 0s 257us/step - loss: 0.3230 - acc: 0.9600\n",
            "Epoch 73/90\n",
            "150/150 [==============================] - 0s 236us/step - loss: 0.3187 - acc: 0.9600\n",
            "Epoch 74/90\n",
            "150/150 [==============================] - 0s 250us/step - loss: 0.3156 - acc: 0.9600\n",
            "Epoch 75/90\n",
            "150/150 [==============================] - 0s 271us/step - loss: 0.3116 - acc: 0.9800\n",
            "Epoch 76/90\n",
            "150/150 [==============================] - 0s 225us/step - loss: 0.3083 - acc: 0.9667\n",
            "Epoch 77/90\n",
            "150/150 [==============================] - 0s 227us/step - loss: 0.3051 - acc: 0.9667\n",
            "Epoch 78/90\n",
            "150/150 [==============================] - 0s 261us/step - loss: 0.3019 - acc: 0.9600\n",
            "Epoch 79/90\n",
            "150/150 [==============================] - 0s 278us/step - loss: 0.2996 - acc: 0.9667\n",
            "Epoch 80/90\n",
            "150/150 [==============================] - 0s 246us/step - loss: 0.2978 - acc: 0.9667\n",
            "Epoch 81/90\n",
            "150/150 [==============================] - 0s 275us/step - loss: 0.2917 - acc: 0.9733\n",
            "Epoch 82/90\n",
            "150/150 [==============================] - 0s 262us/step - loss: 0.2898 - acc: 0.9600\n",
            "Epoch 83/90\n",
            "150/150 [==============================] - 0s 260us/step - loss: 0.2854 - acc: 0.9667\n",
            "Epoch 84/90\n",
            "150/150 [==============================] - 0s 262us/step - loss: 0.2874 - acc: 0.9533\n",
            "Epoch 85/90\n",
            "150/150 [==============================] - 0s 259us/step - loss: 0.2814 - acc: 0.9667\n",
            "Epoch 86/90\n",
            "150/150 [==============================] - 0s 278us/step - loss: 0.2769 - acc: 0.9600\n",
            "Epoch 87/90\n",
            "150/150 [==============================] - 0s 319us/step - loss: 0.2730 - acc: 0.9733\n",
            "Epoch 88/90\n",
            "150/150 [==============================] - 0s 264us/step - loss: 0.2700 - acc: 0.9733\n",
            "Epoch 89/90\n",
            "150/150 [==============================] - 0s 264us/step - loss: 0.2664 - acc: 0.9667\n",
            "Epoch 90/90\n",
            "150/150 [==============================] - 0s 247us/step - loss: 0.2650 - acc: 0.9733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp8wlK88KiNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmY7xzZSLDAc",
        "colab_type": "code",
        "outputId": "745beda8-7fbd-4012-9f75-c450f9a66ec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('model accuraccy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['all'],loc='upper left')\n",
        "plt.savefig('acc.png')\n",
        "plt.show()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx4KCMcYYHwsKxhhjfCwoGGOM8fn/HEy1i1WIALoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx8igrLLLafq",
        "colab_type": "code",
        "outputId": "f1ef0cad-3685-410d-f35f-3aba9b8600e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X_input,dummy_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 0s 700us/step\n",
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}